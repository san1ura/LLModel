{
  "vocab_size": 32000,
  "d_model": 768,
  "n_layers": 12,
  "n_heads": 12,
  "d_ff": 3072,
  "max_len": 2048,
  "dropout": 0.1,
  "pad_token_id": 0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "use_rope": true,
  "pos_type": "rope",
  "use_gradient_checkpointing": false,
  "attention_type": "standard",
  "norm_first": true,
  "initializer_range": 0.02,
  "rms_norm_eps": 1e-06,
  "use_parallel_ffn": false,
  "tie_word_embeddings": false
}