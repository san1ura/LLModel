torch>=2.0.0
gradio>=3.0.0
transformers>=4.21.0
datasets>=2.0.0
sentencepiece>=0.1.98
numpy>=1.21.0
tokenizers>=0.13.0
scikit-learn>=1.0.0
pandas>=1.3.0
tqdm>=4.64.0
scipy>=1.7.0
matplotlib>=3.5.0
# For GPU support
accelerate>=0.12.0
wandb>=0.13.0  # Optional: for experiment tracking
# flash-attn>=2.0.0  # Optional: for faster attention (commented out for easier installation)
bitsandbytes>=0.39.0  # Optional: for 8-bit optimization
peft>=0.4.0  # Optional: for parameter efficient fine-tuning

# API dependencies
fastapi>=0.104.0
uvicorn>=0.24.0
pydantic>=2.5.0